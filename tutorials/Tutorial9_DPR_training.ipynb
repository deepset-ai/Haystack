{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training Your Own \"Dense Passage Retrieval\" Model\n",
    "\n",
    "EXECUTABLE VERSION: [colab](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial9_DPR_training.ipynb)\n",
    "\n",
    "Haystack contains all the tools needed to train your own Dense Passage Retrieval model.\n",
    "This tutorial will guide you through the steps required to create a retriever that is specifically tailored to your domain.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/06/2021 16:32:35 - INFO - faiss -   Loading faiss with AVX2 support.\n",
      "01/06/2021 16:32:35 - INFO - faiss -   Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "# Here are some imports that we'll need\n",
    "\n",
    "from haystack.retriever.dense import DensePassageRetriever\n",
    "from haystack.preprocessor.utils import fetch_archive_from_http"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Data\n",
    "\n",
    "DPR training performed using Information Retrieval data.\n",
    "More specifically, you want to feed in pairs of queries and relevant documents.\n",
    "\n",
    "To train a model, we will need a dataset that has the same format as the original DPR training data.\n",
    "Each data point in the dataset should have the following dictionary structure.\n",
    "\n",
    "``` python\n",
    "    {\n",
    "        \"dataset\": str,\n",
    "        \"question\": str,\n",
    "        \"answers\": list of str\n",
    "        \"positive_ctxs\": list of dictionaries of format {'title': str, 'text': str, 'score': int, 'title_score': int, 'passage_id': str}\n",
    "        \"negative_ctxs\": list of dictionaries of format {'title': str, 'text': str, 'score': int, 'title_score': int, 'passage_id': str}\n",
    "        \"hard_negative_ctxs\": list of dictionaries of format {'title': str, 'text': str, 'score': int, 'title_score': int, 'passage_id': str}\n",
    "    }\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Question Answering Data\n",
    "\n",
    "Question Answering datasets can sometimes be used as training data.\n",
    "Google's Natural Questions dataset, is sufficiently large\n",
    "and contains enough unique passages, that it can be converted into a DPR training set.\n",
    "This is done simply by considering answer containing passages as relevant documents to the query.\n",
    "\n",
    "The SQuAD dataset, however, is not as suited to this use case since its question and answer pairs\n",
    "are created on only a very small slice of wikipedia documents."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download Original DPR Training Data\n",
    "\n",
    "WARNING: These files are large! The train set is 7.4GB and the dev set is 800MB\n",
    "\n",
    "We can download the original DPR training data with the following cell.\n",
    "Note that this data is probably only useful if you are trying to train from scratch."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download original DPR data\n",
    "# WARNING: the train set is 7.4GB and the dev set is 800MB\n",
    "\n",
    "doc_dir = \"data/dpr_training\"\n",
    "\n",
    "s3_url_train = \"https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz\"\n",
    "s3_url_dev = \"https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-dev.json.gz\"\n",
    "\n",
    "fetch_archive_from_http(s3_url_train, output_dir=doc_dir)\n",
    "fetch_archive_from_http(s3_url_dev, output_dir=doc_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Option 1: Training DPR from Scratch\n",
    "\n",
    "The default variables that we provide below are chosen to train a DPR model from scratch.\n",
    "Here, both passage and query embedding models are initialized using BERT base\n",
    "and the model is trained using Google's Natural Questions dataset (in a format specialised for DPR).\n",
    "\n",
    "If you are working in a language other than English,\n",
    "you will want to initialize the passage and query embedding models with a language model that supports your language\n",
    "and also provide a dataset in your language."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Here are the variables to specify our training data, the models that we use to initialize DPR\n",
    "# and the directory where we'll be saving the model\n",
    "\n",
    "doc_dir = \"data/dpr_training\"\n",
    "\n",
    "train_filename = \"biencoder-nq-train.json.gz\"\n",
    "dev_filename = \"biencoder-nq-dev.json.gz\"\n",
    "\n",
    "query_model = \"bert-base-uncased\"\n",
    "passage_model = \"bert-base-uncased\"\n",
    "\n",
    "save_dir = \"..saved_models/dpr\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Option 2: Finetuning DPR\n",
    "\n",
    "If you have your own domain specific question answering or information retrieval dataset,\n",
    "you might instead be interested in finetuning a pretrained DPR model.\n",
    "In this case, you would initialize both query and passage models using the original pretrained model.\n",
    "You will want to load something like this set of variables instead of the ones above"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here are the variables you might want to use instead of the set above\n",
    "# in order to perform pretraining\n",
    "\n",
    "doc_dir = \"PATH_TO_YOUR_DATA_DIR\"\n",
    "train_filename = \"TRAIN_FILENAME\"\n",
    "dev_filename = \"DEV_FILENAME\"\n",
    "\n",
    "query_model = \"facebook/dpr-question_encoder-single-nq-base\"\n",
    "passage_model = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    "\n",
    "save_dir = \"..saved_models/dpr\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization\n",
    "\n",
    "Here we want to initialize our model either with plain language model weights for training from scratch\n",
    "or else with pretrained DPR weights for finetuning.\n",
    "We follow the [original DPR parameters](https://github.com/facebookresearch/DPR#best-hyperparameter-settings)\n",
    "for their max passage length but set max query length to 64 since queries are very rarely longer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/06/2021 16:33:25 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "01/06/2021 16:33:33 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n"
     ]
    }
   ],
   "source": [
    "## Initialize DPR model\n",
    "\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store=None,\n",
    "    query_embedding_model=query_model,\n",
    "    passage_embedding_model=passage_model,\n",
    "    max_seq_len_query=64,\n",
    "    max_seq_len_passage=256\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "Let's start training and save our trained model!\n",
    "\n",
    "How long does it take? e.g. on V100?\n",
    "Batch size / epochs / expected behaviors\n",
    "What is embed title, its in both the DPR constructor and DPR.train()\n",
    "What are decent loss values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Start training our model and save it when it is finished\n",
    "\n",
    "retriever.train(\n",
    "    data_dir=doc_dir,\n",
    "    train_filename=train_filename,\n",
    "    dev_filename=dev_filename,\n",
    "    test_filename=dev_filename,\n",
    "    n_epochs=1,\n",
    "    batch_size=4,\n",
    "    save_dir=save_dir,\n",
    "    embed_title=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading\n",
    "\n",
    "Loading our newly trained model is simple!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reloaded_retriever = DensePassageRetriever.load(save_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "data format\n",
     "Explain what is DPR\n",
     "embed title\n",
     "initialisation\n",
     "- fine tune vs train from scratch (BERT)\n",
     "colab package installation\n",
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}